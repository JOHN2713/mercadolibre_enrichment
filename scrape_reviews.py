from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from pymongo import MongoClient
from dotenv import load_dotenv
import os
import time

load_dotenv()
MONGODB_URI = os.getenv("MONGODB_URI")

if not MONGODB_URI:
    raise ValueError("No se encontr√≥ MONGODB_URI en el .env")

client = MongoClient(MONGODB_URI)
db = client["ml_reviews"]
products_col = db["products"]
reviews_col = db["raw_reviews"]

def setup_driver():
    """Configura el navegador Chrome en modo headless"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def extract_reviews_selenium(driver, url, max_reviews=20):  # Aumentado a 20
    """Extrae rese√±as usando Selenium"""
    print(f"  üîç Cargando p√°gina con Selenium...")
    driver.get(url)
    
    reviews_data = []
    
    try:
        # Esperar a que cargue la p√°gina
        time.sleep(3)
        
        # Scroll para cargar m√°s contenido
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        # Intentar hacer clic en "Ver m√°s opiniones" m√∫ltiples veces
        for _ in range(3):  # Intentar hasta 3 veces
            try:
                ver_mas_btns = driver.find_elements(By.XPATH, 
                    "//button[contains(text(), 'Ver m√°s') or contains(text(), 'opiniones') or contains(text(), 'Mostrar m√°s')]")
                if ver_mas_btns:
                    ver_mas_btns[0].click()
                    print("  ‚úì Click en 'Ver m√°s opiniones'")
                    time.sleep(2)
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)
                else:
                    break
            except:
                break
        
        # Selectores posibles para rese√±as
        review_selectors = [
            "//div[@class='ui-review-capability__comment']",
            "//p[contains(@class, 'ui-review-capability-comments__comment__text')]",
            "//article[contains(@class, 'ui-review')]",
            "//div[contains(@class, 'ui-pdp-review__comment')]",
            "//*[contains(@class, 'review')]//p",
            "//div[contains(@class, 'ui-review-capability-comments__comment')]//p",
        ]
        
        review_elements = []
        for selector in review_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                if elements:
                    review_elements = elements
                    print(f"  ‚úì Encontradas {len(elements)} rese√±as con selector: {selector[:50]}...")
                    break
            except:
                continue
        
        if not review_elements:
            print("  ‚ö†Ô∏è No se encontraron rese√±as con los selectores conocidos")
            # DEBUG: Guardar HTML solo del primer producto sin rese√±as
            if not os.path.exists("debug_product_page.html"):
                with open("debug_product_page.html", "w", encoding="utf-8") as f:
                    f.write(driver.page_source)
                print("  üìÑ P√°gina guardada en debug_product_page.html")
            return []
        
        # Extraer texto de cada rese√±a
        for idx, element in enumerate(review_elements[:max_reviews]):
            try:
                texto = element.text.strip()
                if not texto or len(texto) < 10:
                    continue
                
                # Intentar extraer calificaci√≥n (estrellas)
                rating = None
                try:
                    parent = element.find_element(By.XPATH, "./ancestor::article | ./ancestor::div[@class='ui-review']")
                    rating_elem = parent.find_element(By.XPATH, ".//*[contains(@class, 'rating') or contains(@class, 'stars')]")
                    rating_text = rating_elem.get_attribute("aria-label") or rating_elem.text
                    import re
                    match = re.search(r'(\d+)', rating_text)
                    if match:
                        rating = int(match.group(1))
                except:
                    pass
                
                reviews_data.append({
                    "texto": texto,
                    "puntuacion": rating
                })
                print(f"    ‚úì Rese√±a {idx+1}: {texto[:50]}... | Rating: {rating}")
                
            except Exception as e:
                print(f"    ‚ö†Ô∏è Error extrayendo rese√±a {idx+1}: {e}")
                continue
        
    except Exception as e:
        print(f"  ‚ùå Error general: {e}")
    
    return reviews_data

def scrape_reviews_for_product(driver, product_doc, max_reviews=20):  # Aumentado a 20
    url = product_doc["url_producto"]
    categoria = product_doc.get("categoria")
    titulo = product_doc.get("titulo")

    print(f"\n{'='*80}")
    print(f"üõí Producto: {titulo}")
    print(f"üìÇ Categor√≠a: {categoria}")
    print(f"üîó URL: {url}")

    # Verificar si ya tiene rese√±as en la BD
    existing_count = reviews_col.count_documents({"producto_mongo_id": product_doc["_id"]})
    if existing_count > 0:
        print(f"  ‚ÑπÔ∏è Este producto ya tiene {existing_count} rese√±as. Saltando...")
        return

    reviews = extract_reviews_selenium(driver, url, max_reviews)

    if not reviews:
        print("  ‚ö†Ô∏è No se encontraron rese√±as para este producto.")
        return

    docs_to_insert = []
    for r in reviews:
        doc = {
            "producto_mongo_id": product_doc["_id"],
            "categoria": categoria,
            "url_producto": url,
            "titulo_producto": titulo,
            "rese√±a_texto": r["texto"],
            "puntuacion": r["puntuacion"],
            "origen": "mercadolibre_reviews"
        }
        docs_to_insert.append(doc)

    result = reviews_col.insert_many(docs_to_insert)
    print(f"‚úÖ Insertadas {len(result.inserted_ids)} rese√±as en MongoDB.")

def main():
    # Obtener TODOS los productos (sin limit)
    productos = list(products_col.find())

    if not productos:
        print("‚ùå No hay productos en la colecci√≥n 'products'.")
        print("   Ejecuta primero scrape_products.py")
        return

    print(f"üìä Total de productos a procesar: {len(productos)}")
    print(f"üìä Rese√±as actuales en BD: {reviews_col.count_documents({})}")

    driver = setup_driver()
    
    try:
        productos_procesados = 0
        rese√±as_totales = 0
        
        for idx, p in enumerate(productos, 1):
            print(f"\n[{idx}/{len(productos)}]")
            before_count = reviews_col.count_documents({})
            scrape_reviews_for_product(driver, p, max_reviews=20)
            after_count = reviews_col.count_documents({})
            
            nuevas_rese√±as = after_count - before_count
            if nuevas_rese√±as > 0:
                productos_procesados += 1
                rese√±as_totales += nuevas_rese√±as
            
            time.sleep(3)  # Pausa entre productos
            
    finally:
        driver.quit()
        print(f"\n{'='*80}")
        print(f"üèÅ Scraping completado.")
        print(f"‚úÖ Productos con rese√±as: {productos_procesados}/{len(productos)}")
        print(f"‚úÖ Total de rese√±as obtenidas: {rese√±as_totales}")
        print(f"üìä Total en BD: {reviews_col.count_documents({})}")

if __name__ == "__main__":
    main()
